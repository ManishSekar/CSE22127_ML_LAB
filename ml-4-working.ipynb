{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565ebaa9-705e-4dd1-8d05-5b2f77423d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix:\n",
      "[[37  0  0 ...  0  0  0]\n",
      " [ 0 24  0 ...  0  0  0]\n",
      " [ 0  0 39 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 38  0  0]\n",
      " [ 0  0  0 ...  0 37  0]\n",
      " [ 0  0  0 ...  0  0 28]]\n",
      "\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        3333       1.00      1.00      1.00        37\n",
      "        3334       1.00      1.00      1.00        24\n",
      "        3335       1.00      1.00      1.00        39\n",
      "        3337       1.00      1.00      1.00        28\n",
      "        3342       1.00      1.00      1.00        33\n",
      "        3346       1.00      1.00      1.00        33\n",
      "        3349       1.00      1.00      1.00        52\n",
      "        3351       0.75      0.86      0.80        28\n",
      "        3352       0.73      0.58      0.65        19\n",
      "        3353       1.00      1.00      1.00        28\n",
      "        3354       1.00      1.00      1.00        49\n",
      "        3356       1.00      1.00      1.00        39\n",
      "        3359       1.00      1.00      1.00        44\n",
      "        3360       1.00      1.00      1.00        37\n",
      "        3361       1.00      1.00      1.00        11\n",
      "        3362       1.00      1.00      1.00        17\n",
      "        3363       1.00      1.00      1.00        33\n",
      "        3364       1.00      1.00      1.00        61\n",
      "        3365       1.00      1.00      1.00        25\n",
      "        3366       1.00      1.00      1.00        38\n",
      "        3367       1.00      1.00      1.00        33\n",
      "        3368       1.00      1.00      1.00        66\n",
      "        3370       1.00      1.00      1.00        38\n",
      "        3371       1.00      1.00      1.00        24\n",
      "        3372       1.00      1.00      1.00        28\n",
      "        3373       1.00      1.00      1.00        31\n",
      "        3374       1.00      1.00      1.00        57\n",
      "        3375       1.00      1.00      1.00        50\n",
      "        3376       1.00      1.00      1.00        64\n",
      "        3377       1.00      1.00      1.00        47\n",
      "        3378       1.00      1.00      1.00        40\n",
      "        3379       1.00      1.00      1.00        42\n",
      "        3380       1.00      1.00      1.00        13\n",
      "        3381       1.00      1.00      1.00        56\n",
      "        3382       1.00      1.00      1.00        31\n",
      "        3383       1.00      1.00      1.00        40\n",
      "        3384       1.00      1.00      1.00        45\n",
      "        3385       1.00      1.00      1.00        42\n",
      "        3450       1.00      1.00      1.00        12\n",
      "        3451       1.00      1.00      1.00        38\n",
      "        3452       1.00      1.00      1.00        38\n",
      "        3453       1.00      1.00      1.00        37\n",
      "        3454       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           0.99      1575\n",
      "   macro avg       0.99      0.99      0.99      1575\n",
      "weighted avg       0.99      0.99      0.99      1575\n",
      "\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[11  0  0 ...  0  0  0]\n",
      " [ 0 13  0 ...  0  0  0]\n",
      " [ 0  0 15 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 19  0  0]\n",
      " [ 0  0  0 ...  0 10  0]\n",
      " [ 0  0  0 ...  0  0 11]]\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        3333       1.00      0.73      0.85        15\n",
      "        3334       1.00      1.00      1.00        13\n",
      "        3335       1.00      1.00      1.00        15\n",
      "        3337       1.00      1.00      1.00         7\n",
      "        3342       1.00      0.95      0.98        22\n",
      "        3343       0.00      0.00      0.00         1\n",
      "        3346       1.00      1.00      1.00        12\n",
      "        3349       0.93      0.87      0.90        30\n",
      "        3350       0.00      0.00      0.00         1\n",
      "        3351       0.10      0.20      0.13        10\n",
      "        3352       0.11      0.05      0.07        19\n",
      "        3353       1.00      1.00      1.00        19\n",
      "        3354       0.88      0.95      0.91        22\n",
      "        3355       0.00      0.00      0.00         1\n",
      "        3356       1.00      0.93      0.96        14\n",
      "        3357       0.00      0.00      0.00         1\n",
      "        3358       0.00      0.00      0.00         1\n",
      "        3359       1.00      0.80      0.89        25\n",
      "        3360       0.50      1.00      0.67         9\n",
      "        3361       1.00      1.00      1.00         5\n",
      "        3362       1.00      1.00      1.00         5\n",
      "        3363       0.81      1.00      0.90        13\n",
      "        3364       0.83      0.91      0.87        11\n",
      "        3365       0.86      1.00      0.92         6\n",
      "        3366       0.88      0.94      0.91        16\n",
      "        3367       0.92      1.00      0.96        12\n",
      "        3368       0.81      1.00      0.90        26\n",
      "        3370       0.92      1.00      0.96        12\n",
      "        3371       1.00      1.00      1.00         6\n",
      "        3372       0.90      1.00      0.95         9\n",
      "        3373       0.94      1.00      0.97        16\n",
      "        3374       0.96      0.93      0.95        29\n",
      "        3375       0.87      0.76      0.81        17\n",
      "        3376       0.89      0.93      0.91        27\n",
      "        3377       0.95      0.82      0.88        22\n",
      "        3378       0.94      0.68      0.79        22\n",
      "        3379       1.00      0.85      0.92        13\n",
      "        3380       1.00      1.00      1.00         4\n",
      "        3381       0.74      0.96      0.84        24\n",
      "        3382       0.89      1.00      0.94        16\n",
      "        3383       1.00      0.88      0.93        16\n",
      "        3384       1.00      0.76      0.86        21\n",
      "        3385       0.88      1.00      0.94        22\n",
      "        3450       1.00      1.00      1.00         7\n",
      "        3451       0.89      1.00      0.94        17\n",
      "        3452       1.00      0.90      0.95        21\n",
      "        3453       0.91      1.00      0.95        10\n",
      "        3454       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           0.88       675\n",
      "   macro avg       0.80      0.81      0.80       675\n",
      "weighted avg       0.88      0.88      0.88       675\n",
      "\n",
      "\n",
      "--- Model Analysis ---\n",
      "Model might be overfitting the data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuvra\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yuvra\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yuvra\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "##### A1 #####\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"D:/DCT_withoutduplicate 3 (1).csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the last column is the target variable\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a classification model (Random Forest in this case)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on training data\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Predictions on test data\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate on training data\n",
    "train_conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "train_classification_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Evaluate on test data\n",
    "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "print(\"\\nTraining Classification Report:\")\n",
    "print(train_classification_report)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(test_conf_matrix)\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(test_classification_report)\n",
    "\n",
    "# Analysis for overfitting/underfitting:\n",
    "def analyze_model(train_report, test_report):\n",
    "    print(\"\\n--- Model Analysis ---\")\n",
    "    train_f1 = float(train_report.split()[-2])\n",
    "    test_f1 = float(test_report.split()[-2])\n",
    "    \n",
    "    if test_f1 < train_f1 and test_f1 < 0.6:\n",
    "        print(\"Model is likely underfitting the data.\")\n",
    "    elif test_f1 < train_f1:\n",
    "        print(\"Model might be overfitting the data.\")\n",
    "    else:\n",
    "        print(\"Model seems to be fitting well (regular fit).\")\n",
    "\n",
    "analyze_model(train_classification_report, test_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f95c853-5649-4af0-8c07-7d9a098f09fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RMSE: 0.00\n",
      "MAPE: 0.00%\n",
      "R2 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "####### A2 #########\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'C:/Users/yuvra/Downloads/Lab Session Data (1).xlsx'\n",
    "df1 = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming the sheet contains columns 'Candies (#)', 'Mangoes (Kg)', 'Milk Packets (#)', 'Payment (Rs)'\n",
    "X = df1[['Candies (#)', 'Mangoes (Kg)', 'Milk Packets (#)']]\n",
    "y = df1['Payment (Rs)']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAPE: {mape * 100:.2f}%\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d16abd-ae3a-4413-9a48-24fcda337d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### A3 ###\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Given unit prices\n",
    "price_candies = 55\n",
    "price_mangoes = 1\n",
    "price_milk_packets = 18\n",
    "\n",
    "# Function to calculate total bill and classify as 'rich' or 'poor'\n",
    "def calculate_total_bill(X1, X2, X3):\n",
    "    return X1 * price_candies + X2 * price_mangoes + X3 * price_milk_packets\n",
    "\n",
    "# Task A3: Generate Training Data\n",
    "n_points = 20\n",
    "X1_train = np.random.randint(1, 30, size=n_points)  # Candies (#)\n",
    "X2_train = np.random.randint(1, 10, size=n_points)  # Mangoes (Kg)\n",
    "X3_train = np.random.randint(1, 5, size=n_points)   # Milk Packets (#)\n",
    "Y_train = calculate_total_bill(X1_train, X2_train, X3_train)\n",
    "y_train = np.where(Y_train > 200, 1, 0)  # 1 for 'rich' (Y > 200), 0 for 'poor' (Y <= 200)\n",
    "\n",
    "# Plot training data\n",
    "colors = np.where(y_train == 0, 'blue', 'red')\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X1_train, Y_train, c=colors, marker='o', edgecolors='k', label=['Poor (Blue)', 'Rich (Red)'])\n",
    "plt.title('Training Data')\n",
    "plt.xlabel('Candies (#)')\n",
    "plt.ylabel('Total Bill (Rs Y)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39370565-a351-4b4a-aed7-bfd36ac40913",
   "metadata": {},
   "outputs": [],
   "source": [
    "### A4 ###\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "X1_test = np.random.randint(1, 30)   \n",
    "X2_test = np.random.randint(1, 10)   \n",
    "X3_test = np.random.randint(1, 5)    \n",
    "Y_test = calculate_total_bill(X1_test, X2_test, X3_test)\n",
    "test_point = np.array([[X1_test, X2_test, X3_test]])\n",
    "\n",
    "k = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "X_train_full = np.column_stack((X1_train, X2_train, X3_train))\n",
    "knn.fit(X_train_full, y_train)\n",
    "\n",
    "y_pred = knn.predict(test_point)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X1_train, Y_train, c=colors, marker='o', edgecolors='k', label=['Poor (Blue)', 'Rich (Red)'])\n",
    "plt.scatter(X1_test, Y_test, c='green', marker='x', label='Test Point')\n",
    "plt.title(f'Training Data with Test Point Prediction (k={k})')\n",
    "plt.xlabel('Candies (#)')\n",
    "plt.ylabel('Total Bill (Rs Y)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "if y_pred == 0:\n",
    "    print(f'Test point is classified as Poor (Blue)')\n",
    "else:\n",
    "    print(f'Test point is classified as Rich (Red)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7348defd-3ed7-4b51-9a3b-2bf9182c82db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k | Accuracy | Precision | Recall | F1 Score\n",
      "--|----------|-----------|--------|----------\n",
      "1 | 1.00     | 1.00     | 1.00  | 1.00\n",
      "3 | 0.90     | 1.00     | 0.75  | 0.86\n",
      "5 | 0.90     | 1.00     | 0.75  | 0.86\n",
      "7 | 0.80     | 1.00     | 0.50  | 0.67\n",
      "9 | 0.60     | 0.00     | 0.00  | 0.00\n"
     ]
    }
   ],
   "source": [
    "### A5 ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Prepare the training data\n",
    "data = {\n",
    "    'Candies': [20, 16, 27, 19, 24, 22, 15, 18, 21, 16],\n",
    "    'Mangoes': [6, 3, 6, 1, 4, 1, 4, 4, 1, 2],\n",
    "    'Milk Packets': [2, 6, 2, 2, 2, 5, 2, 2, 4, 4],\n",
    "    'Payment': [386, 289, 393, 110, 280, 167, 271, 274, 148, 198],\n",
    "    'ANV': [1, 1, 1, 0, 1, 0, 0, 0, 0, 0]  # Assuming ANV is a binary classification column\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df[['Candies', 'Mangoes']].values\n",
    "y = df['ANV'].values  # Assuming 'ANV' is the target variable for classification\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# List of k values to evaluate\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "# Loop through each k value, train the model, and calculate metrics\n",
    "results = []\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X, y)\n",
    "    y_pred = knn.predict(X)\n",
    "    \n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, zero_division=0)\n",
    "    recall = recall_score(y, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y, y_pred, zero_division=0)\n",
    "    \n",
    "    results.append({\n",
    "        'k': k,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    })\n",
    "\n",
    "# Print the results\n",
    "print(\"k | Accuracy | Precision | Recall | F1 Score\")\n",
    "print(\"--|----------|-----------|--------|----------\")\n",
    "for result in results:\n",
    "    print(f\"{result['k']} | {result['accuracy']:.2f}     | {result['precision']:.2f}     | {result['recall']:.2f}  | {result['f1_score']:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26537527-bb20-4c9b-929f-642614233bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k value from GridSearchCV: 1 with accuracy: 0.8756\n",
      "Best k value from RandomizedSearchCV: 1 with accuracy: 0.8756\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"D:/DCT_withoutduplicate 3 (1).csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assume the last column is the target and the rest are features\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV or RandomizedSearchCV\n",
    "param_grid = {'n_neighbors': list(range(1, 31))}\n",
    "\n",
    "# Option 1: Use GridSearchCV\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_k_grid = grid_search.best_params_['n_neighbors']\n",
    "\n",
    "# Option 2: Use RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(knn, param_distributions=param_grid, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_k_random = random_search.best_params_['n_neighbors']\n",
    "\n",
    "# Evaluate the best models on the test set\n",
    "knn_best_grid = KNeighborsClassifier(n_neighbors=best_k_grid)\n",
    "knn_best_grid.fit(X_train, y_train)\n",
    "y_pred_grid = knn_best_grid.predict(X_test)\n",
    "accuracy_grid = accuracy_score(y_test, y_pred_grid)\n",
    "\n",
    "knn_best_random = KNeighborsClassifier(n_neighbors=best_k_random)\n",
    "knn_best_random.fit(X_train, y_train)\n",
    "y_pred_random = knn_best_random.predict(X_test)\n",
    "accuracy_random = accuracy_score(y_test, y_pred_random)\n",
    "\n",
    "print(f\"Best k value from GridSearchCV: {best_k_grid} with accuracy: {accuracy_grid:.4f}\")\n",
    "print(f\"Best k value from RandomizedSearchCV: {best_k_random} with accuracy: {accuracy_random:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb54153-56e2-411f-a3a7-dddfd39ada19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
